---
layout: post
comments: true
title: 深度学习的瓶颈
excerpt: 从计算机视觉的角度来探讨深度学习的瓶颈
categories: Work
date: 2018-02-02 22:00:00
---

##### 一、深度学习缺乏理论支撑
大多数文章的idea都是靠直觉提出来的，背后的很少有理论支撑。通过实验验证有效的idea，不一定是最优方向。就如同最优化问题中的sgd一样，每一个step都是最优，但从全局来看，却不是最优。

没有理论支撑的话，计算机视觉领域的进步就如同sgd一样，虽然有效，但是缓慢；如果有了理论支撑，计算机视觉领域的进步就会像牛顿法一样，有效且迅猛。

CNN模型本身有很多超参数，比如设置几层，每一层设置几个filter，每个filter是depth wise还是point wise，还是普通conv，filter的kernel size设置多大等等。

这些超参数的组合是一个很大的数字，如果只靠实验来验证，几乎是不可能完成的。最后只能凭直觉试其中一部分组合，因此现在的CNN模型只能说效果很好，但是绝对还没达到最优，无论是效果还是效率。

以效率举例，现在resnet效果很好，但是计算量太大了，效率不高。然而可以肯定的是resnet的效率可以提高，因为resnet里面肯定有冗余的参数和冗余的计算，只要我们找到这些冗余的部分，并将其去掉，效率自然提高了。一个最简单而且大多人会用的方法就是减小各层channel的数目。

如果一套理论可以估算模型的capacity，一个任务所需要模型的capacity。那我们面对一个任务的时候，使用capacity与之匹配的模型，就能使得效果好，效率优。

##### 二、领域内越来越工程师化思维
因为深度学习本身缺乏理论，深度学习理论是一块难啃的骨头，深度学习框架越来越傻瓜化，各种模型网上都有开源实现，现在业内很多人都是把深度学习当乐高用。

面对一个任务，把当前最好的几个模型的开源实现git clone下来，看看这些模型的积木搭建说明书（也就是论文），思考一下哪块积木可以改一改，积木的顺序是否能调换一样，加几个积木能不能让效果更好，减几个积木能不能让效率更高等等。

思考了之后，实验跑起来，实验效果不错，文章发起来，实验效果不如预期，重新折腾一遍。

这整个过程非常的工程师化思维，基本就是凭感觉trial and error，深度思考缺位。很少有人去从理论的角度思考模型出了什么问题，针对这个问题，模型应该做哪些改进。

举一个极端的例子，一个数据实际上是一次函数，但是我们却总二次函数去拟合，发现拟合结果不好，再用三次函数拟合，三次不行，四次，再不行，就放弃。我们很少思考，这个数据是啥分布，针对这样的分布，有没有函数能拟合它，如果有，哪个函数最合适。

深度学习本应该是一门科学，需要用科学的思维去面对她，这样才能得到更好的结果。

##### 三、对抗样本是深度学习的问题，但不是深度学习的瓶颈
我认为对抗样本虽然是深度学习的问题，但并不是深度学习的瓶颈。机器学习中也有对抗样本，机器学习相比深度学习有着更多的理论支撑，依然没能把对抗样本的问题解决。

之所以我们觉得对抗样本是深度学习的瓶颈是因为，图像很直观，当我们看到两张几乎一样的图片，最后深度学习模型给出两种完全不一样的分类结果，这给我们的冲击很大。

如果修改一个原本类别是A的feature中某个元素的值，然后使得svm的分类改变为B，我们会觉得不以为然，“你改变了这个feature中某个元素的值，它的分类结果改变很正常啊”。
